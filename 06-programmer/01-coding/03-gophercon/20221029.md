Welcome back to GopherCon. It's so nice to be here in person with you all after three long years.

So it's really nice to see this room and to see all your faces and some masks. I'll be masked the rest of the conference, but it's so nice for everyone to be here and I just want to say 'Welcome Back.'

So this talk is about compatibility which I know sounds boring. In fact if this weren't the opening talk, maybe you'd have skipped it. But boring can be good, back in the early days of Go1, Go was exciting and full of surprises, and every week we cut a new release and everyone got to roll the dice and see what we'd broken in their code.

We released Go1 and its compatibility promise to stop that excitement, so that new releases of Go would be boring. Because boring is good, boring is stable, boring means to be able to focus on your work, and not ours.

So today I want to tell you about the important difficult work that we do to keep Go boring. First, we'll look at go1 compatibility and what it does and doesn't mean. Then we'll look at how we on the go team try to avoid breaking your programs. But programs still breaks so we'll look at how they break. And that leads to a few ideas about changes we might make to go to break fewer programs and then I'll finish with an update on Go2.

So let's start with Go1 compatibility.

For Go1, we published a document titled 'Go1 and the Future of Go programs' and it laid out a very clear intention. We wrote it is intended that programs written to the Go1 specification will continue to compile and run correctly unchanged over the lifetime of that specification. And that go programs that work today should continue to work even as future releases of Go happen.

There are a few qualifications to that.

First, compatibility means source compatibility. When you update to a new version of Go, you do have to recompile your code. And second, we can add new APIs but not in a way that breaks existing code. The last part of the document warns, it is impossible to guarantee that no future change will break any program. And then it lays out a number of reasons why programs might still break. For example it should make sense that if your program depends on a buggy behavior and we fix that bug then that breaks your program. But we try very hard to break as little as possible and to keep Go boring.

There are two main approaches we use to keep Go boring. And the first is API checking. Perhaps the clearest fact about compatibility is that we can't take away API or else the programs that use it will break. So here's a program someone has written that we can't break. We can't remove package os. We can't remove the global variable os.Stdout which is an os.File. And we can't remove os.File's method WriteString.

Now it might be a little less clear that we can't even change the type of os.Stdout even if we change it to something else that has all the same methods. This program wouldn't break, but this one would. It passes os.Stdout to a function called Greet and Greet requires an argument of type pointer to os.File. So changing os.Stdout to some other type or to an interface would break this program.

To help us, we use a tool that maintains a list of all the exported API that has been in previous Go releases and that's separate from the packages API and then we run a test that checks that the package API matches those files. If there's a new API, it has to be added to the files and if API gets removed or changed, the test tells us and keeps us honest. But a tool like this only finds API breaks, so even if the tool is happy, there can still be other problems and that leads us to our second approach - testing. 

The most effective way to find unexpected incompatibilities is to test existing programs and tests against new versions of Go. We test the development version of Go against all of Google's internal Go tasks on a rolling basis. And when they're all passing, we install that version of Go even before a release as Google's production go tool chain. Now if a change breaks tests inside Google, we assume it's going to break tests outside Google as well. And we think about whether there are ways to mitigate that I know at least document the potential problem in the release notes.

I want to show you two subtle problems we found when preparing Go 1.1.

Here's some code that runs fine and Go1. Package main declares `MyAddr` which is a composite literal of type `net.TcpAddr` and package `net` defines `TCPAddr` as a struct with two Fields IP and port. These match the composite literal, so the code compiles. In Go1.1 the program stopped compiling even though the program is unchanged the compiler now reports that there are too few initializers in the struct literal. The problem is that Go1.1 added a new field `Zone` and now that there are three fields and untagged literal needs to specify all three.

The solution is to write out our code from the start using tagged literals, specifying that these two values are for the IP and Port fields. Then when Zone is introduced the code, keeps compiling and the literal uses the zero value for Zone. This requirement to use composite literals for the standard library is explicitly called out in compatibility document and `vet` reports these problems. This was new enough in Go1.1 that we left a short description in the release notes but now we would just mention there's a new field.

The second problem we found has nothing to do with APIs, it had to do with time. Shortly after Go1 was released, someone pointed out that time.Now returned microsecond precision but that we could make it use nanosecond precision instead. That sounds good? right? More precision better, so we made that change but that broke a handful of tests inside Google that were kind of like this one where they call time.Now save it reload it and expect to get the same time. If save and load only store microseconds then this test works fine and go one but it fails and go 1.1.

So to help fix tests like this we added round and truncate methods to discard unwanted precision and in the release notes we documented the problem and the new methods.

These examples show how testing finds different kinds of incompatibility than the API checks do of course testing is not a complete guarantee either but it's much more effective than the API checking. these problems in go 1.1 emphasize to us how much of our effort working on go and compatibility would be spent on correct reasonable changes that nonetheless break your programs.

So let's turn our attention to why programs break today, and despite our best efforts.

Most compatibility issues can be placed in one of three categories output changes input changes and protocol changes and we'll look at all three. the most straightforward category is output changes where a function gives a different output that's equally correct or even more correct. but if code is written to expect the old output, it will break. we just saw one example with time.now and nanosecond precision.

Another example happened in go 1.6 where we improved the implementation of sort to make it run about 10 percent faster. now here's an example program it sorts a list of colors by length of name and in go 1.5 it returned green white black in that order those are all equal so they can be returned in any order. And go 1.6 is algorithm turned out to return white green black.

Now again sort is clearly allowed to return equal elements in any order it likes and this algorithm change makes it run 10 faster so that's a win we want to do that. but programs that expect a specific output are going to break. so this is an example of why compatibility is so hard we don't want to break your programs but we also don't want to be locked in to undocumented implementation details.

As another example in go 1.8 we changed compressed Fleet to produce smaller outputs with roughly the same CPU and memory overhead that's a win-win right. well no it wasn't it broke a project inside Google that needed reproducible archive builds. now they couldn't reproduce their old archives so they had to Fork the old compressed plate and the old compressed gzip. so that they could keep building the same bits that they did with earlier versions of go. we do a similar thing with the compiler and sort we use a copy of sort so that no matter what version of go you use the compiler produces the same outputs.

So those are examples of output change incompatibilities. the best answer is to write your code and your tests to accept any valid behavior and to use these breakages as an opportunity to revise your test to do that. but if you need truly reproducible outputs the next best answer is to Fork the code to insulate yourself from changes but note that you're also insulating yourself from bug fixes.

The next category is input changes. where a function changes which inputs it accepts or how it processes them.

For example Go1.13 added support for underscores and numbers for readability and at the same time we updated stirconf.parsint to handle the new ghost syntax. This didn't break anything inside Google but I heard recently from a user whose code it did break. they were using numbers separated by underscores as a data format and they only looked for the underscores when parsaint failed. so when Parsons stopped failing their underscore processing stopped getting run.

As another example when I wrote net.parseip I followed the examples in the early rfcs which showed decimal addresses with leading zeros sometimes. so this address in go is 18.32.4.11 with a couple zeros mixed in. I found out later that most C libraries interpret that leading zero as meaning this is an octal number making the same input 18.26.4.9. this is a serious mismatch between go and the rest of the world but changing the meaning of leading zeros from one go release to the next would also be a serious mismatch. it would be a huge incompatibility. so what we did instead is in go 117 we changed parse IP to reject IP addresses with leading zeros outright. this way if go and see both successfully parse an IP address they agree on what it means.

Now, this change didn't break anything inside Google but the kubernetes team is concerned that saved configurations might have used these addresses and now they wouldn't parse anymore with the new go. now those addresses probably should be removed from the configurations because go reads them differently than most other software. but that should happen on kubernetes timeline and not on ours. and So to avoid the semantic change kubernetes forked net.parse IP to get keep make a copy of the original.

Those are some examples of input change incompatibilities and the best answer to those is to process user input to validate the syntax before you call the General parser. and sometimes you do need to Fork the code.

now the parsaint and parse IP changes where input changes for go but in their systems they were protocol changes which is the next topic. a protocol change is a change that's made to a package that ends up externally visible in the protocols a program uses to communicate with the outside world. almost any change can become externally visible as we just saw but I'm talking here about changes that are externally visible in almost all programs.

A clear example is when go 1.6 added support for HTTP 2. here we have two go programs talking to each other across the internet using HTTP 1.1 when they both update to 1.6 they'll start using http 2. 

Now, due to some problem, these Gophers have no control over, there's some middle box that's breaking their HTTP 2 sessions and they can't talk anymore. clearly go must support modern protocol versions but at the same time enabling them can break programs like this. now don't worry the cloud Gophers know about the problem and they're working to fix it but what can the other Gophers do while they wait. they could go back to go 1.5 but that's not very satisfactory.

So instead Go 1.6 documented the change as well as ways to opt out, there were two ways first you can make source code changes in your program to disable the hp2 client or the server or both and you could also set a go debug environment variable at runtime to have the same effect. here's a subtler example of a protocol change. no one should be using sha-1 certificates for https anymore. certificate authorities stopped issuing them in 2015 browsers stopped accepting them in 2017 and so go remove support earlier this year with a goatee bug to turn them back on. and we announced that we were going to remove the goatee bug in the next release.

The kubernetes team let us know that some private installations are still using private sha-1 certificates and putting aside the security problems it's not kubernetes place to force these Enterprises to upgrade their certificate infrastructure on kubernetes schedule or on goes. and it'll be very painful for kubernetes to Fork TLS and HTTP just to keep support. so we agreed to keep the override in place for longer to create time for an orderly transition. after all we want to break as few programs as possible.

So let's turn our attention to changes we might make to go to do that to break fewer programs. there are three different ideas I want to show you. one each for backward compatibility forward compatibility and language compatibility. backward compatibility means new go tool chains building old go programs. we want those programs to continue to work exactly as before or at least as close as possible and we think we can make that happen more often by expanding our use of go debug.

First we would guarantee that at a go debug setting anytime we make a compatible change that nonetheless breaks existing programs. second we guarantee that these settings would last at least two years. although some may last even longer we're not planning to remove the HTTP 2 overrides. And third whenever possible we provide runtime metrics counters to count the number of times that the go debug setting changed the way the program would have behaved. so that users can monitor whether they're still making use of the old settings or not. fourth we provide a way to set specific goatee bugs in source code so that a binary can have its own defaults independent of the environment because it applies to the whole program these lines would only have effect in package Main but it would let people distribute programs and not have to tell them oh to keep this program running you have to set this environment variable.

Of course there's still the problem of knowing which goatee bugs you should set. so Fifth and last we derive the default goatee bug settings from the Go version in the main modules Godot mod. so if your project has a go.mod file that says go 117. the latest version of go turns out to be the best implementation of go 117 available. it has all the latest bug fixes and stability fixes and optimizations, but when compiling a go 117 program it still provides the go 117 semantics above and beyond the compatibility promise. that's backwards compatibility.

Now what about forwards compatibility which is old versions of go trying to compile newer programs.

Today, an older version of Go will do a best effort attempt to compile programs that have go lines listing newer versions. if the build succeeds, the go command assumes everything worked but if the build fails usually with a mysterious error that somehow says I don't understand your program. The Go command prints a note at the end that says you know by the way there's this version mismatch. this approach only helps if the new code definitely doesn't compile with the old go. and the failure is printed before the note are very confusing for users. so we'd like to improve this experience. the way to do that is for an older Go version to notice that the code is newer and then download and re-exec an appropriate version of go when the go.mod file asks for one.

So in this example the go command sees that it's too old and it downloads and runs go 118 instead. now to be clear go 117 does not work this way but we're thinking about maybe some future version of go should. so this is not going to be in the next release but it's something we're considering.

And speaking of things that are not going to be the next release but that we're considering, let's talk about language compatibility. the go debug settings we just saw are limited because they have to apply at runtime to the whole program. there's no coherent way for net.parse IP to behave one way when called from one package on a different way when called from a different package. but language compatibility is easier because it affects compile time decisions so we can change them on a per package basis. in fact we already do this in a limited way when the go command compiles any package it tells the compiler what Go version that packages go.mod says and then the compiler tailors the language.

So in this example the main module says go 119 so we can use generics and it can use numbers with underscores. but its dependency module a says go 117 so the packages in a can use numbers with underscores but not generics and the dependency module B says go 112 so we can't use either one of those new features. we could use this same mechanism to remove or fix sharp Corners in the language that repeatedly cause problems.

For example we saw that the very first compatibility problem we had in go 1 involved untagged struck literals now go vet has reported cross package untagged literals ever since and that created an ecosystem convention but not a hard rule. we could strengthen that convention to a rule by using the per module Go version. We could decide that in some future version of go modules using that version or later have to use Tag tags in cross-package literals.

So in this example the main module says go 130 so it has to use tagged cross package literals but its dependencies have older Go versions and they can keep using the untagged forms this ensures that new code that gets written avoids pitfalls but the old code continues to build. and when you update your module to the new Go version there will be a tool to completely automatically update the code. the pattern here would be that we can remove problem features from the language but we can't redefine them however there is one exception to the no redefinitions rule that I think we should consider and it involves for loops. this is a correct program except that we don't know when the workers finish we might try to fix that by adding a weight group.

Now we know when the workers are done but they're not doing the right work anymore we added above. the original code was correct because the go statement copied K and v as arguments to the function in the new go routine and the new code is buggy because the closure captures and shares the for Loop variables K and V and then they get overwritten on the next iteration of the loop.

So one fix is to pass the variables as arguments to the new go routine and the other fix is to introduce iteration scoped copies of the variables. look we have all made this mistake, there are various Checkers in the ecosystem for this bug that looks for certain patterns but it can't find all of them because it would cause false positives. as well other tools take a different approach over reporting the problem which forces people to write X colon equals x lines that they don't really need.

In fact for some tools the false positive rate can be as high as 90 percent. goes race detector will report the problem in the program we just looked at but it can happen in single threaded programs too and the race detector won't notice. so our decision to use per Loop variables and go is the only one I can think of that in retrospect makes more programs wrong than right and the only complete solution here would be to change the semantics. it would eliminate this class of bugs it would eliminate the need for these incomplete Checkers and it would ensure that no more time and money is wasted on production problems and debugging when people make this mistake.

So I think it might be time to fix this and even better we have a compatible way to roll out the fix. as you've no doubt guessed the way to roll out this change is to use the go.mod Go version lines. if we make the change and go 130 then packages in modules that say go 130 or later would get the new semantics and packages and modules with earlier versions we've got the old semantics and just like with untagged literals old code and new code would coexist in the build. this is the sort of change that we used to push off to go to but modules give us a compatible way to make that change and go one. that takes us to the update on go 2 that I promised.

When I quoted the go one compatibility promise earlier I left out one phrase. that phrase is at some indefinite point a go-to specification may arise but until that time your programs keep working. And so many people have asked the obvious question implied by that phrase when should we expect the go-to specification that's going to break all of our programs. And the answer is never. go to in the sense of breaking with the past and throwing away all the old programs is never going to happen. go to in the sense of being the major revision of go one that we started toward five years ago has already happened but there won't be a go-to that breaks go 1 programs.

Instead we're going to double down on compatibility Which is far more valuable than anything we could get from a break with the past. And in fact I believe that prioritizing compatibility was the most important design decision that we made in go one. so what you'll see over the next few years is minor adjustments like perhaps the untagged literals change and maybe the for Loop fix all keyed off the godotmod go lines. so that existing code continues to compile exactly as it always had and we'll keep calling this go 1.x not go to to emphasize that continuity and backwards compatibility. And we'll keep doing everything we can to keep go boring for all of you.

Thanks very much for being here and joining us today. It's great to see all of you and welcome back to GopherCon.
